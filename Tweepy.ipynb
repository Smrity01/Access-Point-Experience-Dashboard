{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyHamcrest\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/d5/d37fd731b7d0e91afcc84577edeccf4638b4f9b82f5ffe2f8b62e2ddc609/PyHamcrest-1.9.0-py2.py3-none-any.whl (52kB)\n",
      "Requirement already satisfied: six in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from PyHamcrest) (1.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from PyHamcrest) (40.2.0)\n",
      "Installing collected packages: PyHamcrest\n",
      "Successfully installed PyHamcrest-1.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"PyHamcrest\"\n",
    "!pip install \"vaderSentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\tanya\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from tweepy) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from tweepy) (2.19.1)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from tweepy) (1.2.0)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2018.8.24)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tanya\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"tweepy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT ad This year I m buying all my festival essentials from s new shop I m \n",
      "  \n",
      "\n",
      "\n",
      "Amazon sets up temp AmazonLockers site at Coachella creates a special online spot for concert goers to find amp o \n",
      " New York, NY \n",
      "\n",
      "\n",
      "NEWSALERT Walmart Is Beating Amazon in a Business Worth 35 Billion states \n",
      " London \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- Changes :\n",
    "-At line - 66\n",
    "  Replaced searchItem variable with a list.\n",
    "\n",
    "  Problems to deal with:\n",
    "-------------------------------\n",
    "\n",
    "- At line - 72\n",
    "    Its possible that the location is a city in USA but this code will only consider the location string containing 'USA'\n",
    "        which is not correct.\n",
    "'''\n",
    "\n",
    "\n",
    "import tweepy\n",
    "import re\n",
    "import csv\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "class Twitter():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console o get tweets from twitter\n",
    "        consumerKey    = '8WjP9Q9vu94yEhFMs2YIgVZp5'\n",
    "        consumerSecret = 'scv2Ic3jhnFQMKJuI6NoyGfaxmSteSQMySSOxmAgSc8K1ufTOU'\n",
    "        '''\n",
    "        These Tokens are for activities such as tweet, like, retweet, etc.\n",
    "        access_token = '3548080632-xT2YIjmeVxrlnnJJmt9z5uBMADYPlfBU2Bxieks'\n",
    "        access_token_secret = 'Y22P9HnY46Jqnz0M2t1XofhcKbJvdZ7s8wO05ufS56vEV'\n",
    "        '''\n",
    "        # Authentication Try-Catch Block OR print error (if any)\n",
    "        try:\n",
    "            # create OAuthHandler object and create tweepy API object to fetch tweets\n",
    "            self.authentication = tweepy.OAuthHandler(consumerKey,consumerSecret)\n",
    "            self.apiObject = tweepy.API(self.authentication)\n",
    "        except tweepy.TweepError as error:\n",
    "            print(\"Error : \" + str(error))\n",
    "\n",
    "    def cleanTweet(self,tweet):\n",
    "        '''\n",
    "        Clean tweet by removing extra charaters or html tags\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def getTweets(self, query):\n",
    "        '''\n",
    "        ------Main function to fetch tweets and parse them-------\n",
    "        -  Call twitter api to fetch tweets using search function refer README for details.\n",
    "                request('search/tweets', {'q': query}) thiscan also be used\n",
    "\n",
    "        '''\n",
    "        tweetList = [] \n",
    "        fetchedTweets = []\n",
    "        \n",
    "        try:\n",
    "            for i in query:\n",
    "                fetchedTweets += self.apiObject.search(q = i)\n",
    "            # parsing tweets one by one\n",
    "                for tweet in fetchedTweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                    parsedTweet = {}\n",
    "                # saving clean text and location of tweet in the form of dictionary into Tweet list\n",
    "                parsedTweet['text'] = self.cleanTweet(tweet.text)\n",
    "                parsedTweet['location'] = tweet.user.location\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsedTweet not in tweetList:\n",
    "                        tweetList.append(parsedTweet)\n",
    "                else:\n",
    "                    tweetList.append(parsedTweet)\n",
    " \n",
    "            # return Final list of clean tweets and there locations\n",
    "            return tweetList\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Error : \" + str(e))\n",
    "            \n",
    "    def sentiment_scores(self , sentence): \n",
    "        #print sentence\n",
    "        #print(sentence)\n",
    "        # Create a SentimentIntensityAnalyzer object. \n",
    "        sid_obj = SentimentIntensityAnalyzer() \n",
    "        # polarity_scores method of SentimentIntensityAnalyzer \n",
    "        # oject gives a sentiment dictionary. \n",
    "        # which contains pos, neg, neu, and compound scores. \n",
    "        sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "        return sentiment_dict\n",
    "        ''' \n",
    "        print(\"Overall sentiment dictionary is : \", sentiment_dict) \n",
    "        print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\") \n",
    "        print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\") \n",
    "        print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\") \n",
    "\n",
    "        print(\"Sentence Overall Rated As\", end = \" \") \n",
    "\n",
    "        # decide sentiment as positive, negative and neutral \n",
    "        if sentiment_dict['compound'] >= 0.05 : \n",
    "            print(\"Positive\") \n",
    "\n",
    "        elif sentiment_dict['compound'] <= - 0.05 : \n",
    "            print(\"Negative\") \n",
    "\n",
    "        else : \n",
    "            print(\"Neutral\") '''\n",
    "        \n",
    "\n",
    "            \n",
    "    def write_data(self , data) :\n",
    "            TweetsFile = open('tweety.csv', 'a',newline='')\n",
    "            TweetsWriter = csv.writer(TweetsFile , delimiter=',')\n",
    "            TweetsWriter.writerow(['Tweet','Location','User Id','Compound','Negative','Neutral','Positive'])\n",
    "            for tweet in data:\n",
    "                polarity = self.sentiment_scores(tweet['text'])\n",
    "                TweetsWriter.writerow([tweet['text'],tweet['location'],' ',polarity['compound'],polarity['neg']*100,polarity['neu']*100,polarity['pos']*100] )\n",
    "            TweetsFile.close()\n",
    "    \n",
    "            \n",
    "\n",
    "    \n",
    "def main():\n",
    "    # creating object of Twitter Class and class class members to get tweets\n",
    "    twitterObject = Twitter()\n",
    "    searchItem = [\"amazonlocker\",\"amazonlockers\",\"amazon lockers\"]\n",
    "    tweets = twitterObject.getTweets(query = searchItem)\n",
    "    for i in tweets:\n",
    "        #print the tweets from USA\n",
    "        #if 'USA' in i['location']:\n",
    "            print (i['text'],'\\n',i['location'],\"\\n\\n\")\n",
    "            \n",
    "    twitterObject.write_data(tweets)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
